{"config":{"lang":["en"],"separator":"[\\s\\-\\.]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Nirvana: LLM-powered Semantic Data Analytics Programming Framework","text":"<p>Nirvana is an LLM-powered semantic data analytics programming framework that enables semantic data analytics queries over multi-modal data (e.g., text, images, audio). It provides a pandas-like interface with semantic operators that use large language models to process data based on natural language instructions. It also allows an optimizer to find the best execution plan for a given query to strick a balance between quality, runtime, and cost. With Nirvana, users focus only on \"what they want to do\", instead of \"how they achieve it\".</p> <p>Step 0: Install nirvana and set up initial llm</p> via PyPIvia uvfrom source <pre><code>pip install nirvana-ai\n</code></pre> <pre><code>uv pip install nirvana-ai\n</code></pre> <pre><code>pip install git+https://github.com/JunHao-Zhu/nirvana.git\n</code></pre> <p>Before you get started with enjoying features of Nirvana, the first thing to do is to set up a default llm. Taking gpt-4o as an example,you can authenticate by setting the <code>OPENAI_API_KEY</code> env variable or passing <code>api_key</code> below. <pre><code>import nirvana as nv\nnv.configure_llm_backbone(model_name=\"gpt-4o\", api_key=\"YOUR_OPENAI_API_KEY\")\n</code></pre></p>"},{"location":"#apply-semantic-operators-to-dataframe","title":"Apply Semantic Operators to DataFrame","text":"<p>Suppose that you have only a simple semantic processing task on hand, for which you want to apply semantic operators to the data and obtain results in a few lines of code as soon as possible. You can easily use function wrappers of semantic operators on your data frame. Here is an example.</p> <p>Extract the genre from the movie overview</p> <pre><code>df = pd.DataFrame(\n{\n    \"title\": [\"The Godfather\", \"The Dark Knight\"], \n    \"overview\": [\n        \"An organized crime dynasty's aging patriarch transfers control of his clandestine empire to his reluctant son.\", \n        \"When the menace known as the Joker wreaks havoc and chaos on the people of Gotham, Batman must accept one of the greatest psychological and physical tests of his ability to fight injustice.\"\n    ]\n})\nnv.ops.map(df, \"According to the movie overview, extract the genre of each movie.\", input_column=\"overview\", output_columns = [\"genre\"], strategy=\"plain\")\n</code></pre> <p>Possible Output: <pre><code>MapOpOutputs(\n    field_name = [\"genre\"],\n    output = {\"genre\": [\"crime, drama\", \"action, thriller, superhero\"]}\n)\n</code></pre></p> <p>More usages of semantic operators can be found in operators</p>"},{"location":"#enable-query-optimization","title":"Enable Query Optimization","text":"<p>If you have a complex semantic query over large datasets on hand, you probabily want to process the query in a faster, lower-cost way. In this case, Nirvana enables lazy execution and query optimization to automatically find a plan that scales down runtime and monetary costs. Here is a usage example.</p> <pre><code>movie = nv.DataFrame.from_external_file(\"/testdata/movie_data.csv\")\nmovie.semantic_map(user_instruction=\"According to the movie overview, extract the genre of each movie.\", input_column=\"Overview\", output_column=\"Genre\")\nmovie.semantic_filter(user_instruction=\"The rating is higher than 7.\", input_column=\"IMDB_Rating\")\nmovie.semantic_filter(user_instruction=\"The rating is lower than 8.\", input_column=\"IMDB_Rating\")\nmovie.semantic_filter(user_instruction=\"The movie is a crime movie.\", input_column=\"Genre\")\nmovie.semantic_reduce(user_instruction=\"Summerize the common plot structure of these high-rated crime movies.\", input_column=\"Overview\")\n\nconfig = nv.optim.OptimizeConfig(do_logical_optimization=True, do_physical_optimization=True)\nresult, cost, runtime = df.optimize_and_execute(optim_config=config)\n</code></pre> <p>For details and usages of query optimization refers to optimization</p>"},{"location":"api_reference/","title":"API Reference","text":"<p>Complete API reference for Nirvana's core components.</p>"},{"location":"api_reference/#dataframe","title":"DataFrame","text":""},{"location":"api_reference/#nirvanadataframe","title":"<code>nirvana.DataFrame</code>","text":"<p>A DataFrame class that extends pandas DataFrame with semantic operations and data lineage tracking.</p>"},{"location":"api_reference/#constructor","title":"Constructor","text":"<pre><code>DataFrame(data: pd.DataFrame = None, *args, **kwargs)\n</code></pre> <p>Parameters: - <code>data</code> (pd.DataFrame): A pandas DataFrame to wrap</p> <p>Example: <pre><code>import pandas as pd\nimport nirvana as nv\n\ndf = nv.DataFrame(pd.DataFrame({\"col1\": [1, 2, 3]}))\n</code></pre></p>"},{"location":"api_reference/#class-methods","title":"Class Methods","text":""},{"location":"api_reference/#from_external_filepath-str-sep-kwargs-dataframe","title":"<code>from_external_file(path: str, sep=',', **kwargs) -&gt; DataFrame</code>","text":"<p>Load a DataFrame from an external file.</p> <p>Parameters: - <code>path</code> (str): Path to the file - <code>sep</code> (str): Delimiter (default: ',') - <code>**kwargs</code>: Additional arguments passed to <code>pd.read_table()</code></p> <p>Returns: - <code>DataFrame</code>: A new DataFrame instance</p>"},{"location":"api_reference/#properties","title":"Properties","text":"<ul> <li><code>columns</code>: List of column names</li> <li><code>nrows</code>: Number of rows</li> <li><code>primary_key</code>: Primary key column (if set)</li> </ul>"},{"location":"api_reference/#semantic-operations","title":"Semantic Operations","text":""},{"location":"api_reference/#semantic_mapuser_instruction-str-input_column-str-output_column-str-rate_limit-int-16","title":"<code>semantic_map(user_instruction: str, input_column: str, output_column: str, rate_limit: int = 16)</code>","text":"<p>Perform element-wise transformation to create a new column.</p> <p>Parameters: - <code>user_instruction</code> (str): Natural language instruction for the transformation - <code>input_column</code> (str): Column to transform - <code>output_column</code> (str): Name of the new column - <code>rate_limit</code> (int): Maximum concurrent LLM calls (default: 16)</p> <p>Example: <pre><code>df.semantic_map(\n    user_instruction=\"Extract the genre from the overview\",\n    input_column=\"overview\",\n    output_column=\"genre\"\n)\n</code></pre></p>"},{"location":"api_reference/#semantic_filteruser_instruction-str-input_column-str-rate_limit-int-16","title":"<code>semantic_filter(user_instruction: str, input_column: str, rate_limit: int = 16)</code>","text":"<p>Filter rows based on a natural language condition.</p> <p>Parameters: - <code>user_instruction</code> (str): Natural language condition - <code>input_column</code> (str): Column to evaluate - <code>rate_limit</code> (int): Maximum concurrent LLM calls (default: 16)</p> <p>Example: <pre><code>df.semantic_filter(\n    user_instruction=\"Rating is higher than 8.5\",\n    input_column=\"IMDB_Rating\"\n)\n</code></pre></p>"},{"location":"api_reference/#semantic_reduceuser_instruction-str-input_column-str-rate_limit-int-16","title":"<code>semantic_reduce(user_instruction: str, input_column: str, rate_limit: int = 16)</code>","text":"<p>Aggregate values in a column into a single result.</p> <p>Parameters: - <code>user_instruction</code> (str): Natural language aggregation instruction - <code>input_column</code> (str): Column to aggregate - <code>rate_limit</code> (int): Maximum concurrent LLM calls (default: 16)</p> <p>Example: <pre><code>df.semantic_reduce(\n    user_instruction=\"Count the number of crime movies\",\n    input_column=\"genre\"\n)\n</code></pre></p>"},{"location":"api_reference/#semantic_joinother-dataframe-user_instruction-str-left_on-str-right_on-str-how-str-rate_limit-int-16","title":"<code>semantic_join(other: DataFrame, user_instruction: str, left_on: str, right_on: str, how: str, rate_limit: int = 16)</code>","text":"<p>Join two DataFrames based on semantic similarity.</p> <p>Parameters: - <code>other</code> (DataFrame): Right DataFrame to join - <code>user_instruction</code> (str): Natural language join condition - <code>left_on</code> (str): Column from left DataFrame - <code>right_on</code> (str): Column from right DataFrame - <code>how</code> (str): Join type: \"inner\", \"left\", or \"right\" - <code>rate_limit</code> (int): Maximum concurrent LLM calls (default: 16)</p> <p>Example: <pre><code>df1.semantic_join(\n    other=df2,\n    user_instruction=\"Do these match semantically?\",\n    left_on=\"symptom\",\n    right_on=\"medical_use\",\n    how=\"inner\"\n)\n</code></pre></p>"},{"location":"api_reference/#execution-methods","title":"Execution Methods","text":""},{"location":"api_reference/#execute-tuplepddataframe-float-float","title":"<code>execute() -&gt; tuple[pd.DataFrame, float, float]</code>","text":"<p>Execute the query plan along the data lineage.</p> <p>Returns: - <code>tuple</code>: (output DataFrame, total cost, runtime in seconds)</p>"},{"location":"api_reference/#optimize_and_executeoptim_config-optimizeconfig-none-tuplepddataframe-float-float","title":"<code>optimize_and_execute(optim_config: OptimizeConfig = None) -&gt; tuple[pd.DataFrame, float, float]</code>","text":"<p>Optimize and execute the query plan.</p> <p>Parameters: - <code>optim_config</code> (OptimizeConfig): Optimization configuration</p> <p>Returns: - <code>tuple</code>: (output DataFrame, total cost, runtime in seconds)</p>"},{"location":"api_reference/#utility-methods","title":"Utility Methods","text":""},{"location":"api_reference/#print_lineage_graphop_signature_width-int-100-max_instruction_print_length-int-50","title":"<code>print_lineage_graph(op_signature_width: int = 100, max_instruction_print_length: int = 50)</code>","text":"<p>Print a visual representation of the data lineage graph.</p> <p>Parameters: - <code>op_signature_width</code> (int): Width for operator signatures - <code>max_instruction_print_length</code> (int): Max length for instruction display</p>"},{"location":"api_reference/#clear_lineage_graph","title":"<code>clear_lineage_graph()</code>","text":"<p>Clear the data lineage graph.</p>"},{"location":"api_reference/#operators","title":"Operators","text":""},{"location":"api_reference/#direct-operator-usage","title":"Direct Operator Usage","text":"<p>You can also use operators directly without DataFrame:</p>"},{"location":"api_reference/#nirvanaopsmap","title":"<code>nirvana.ops.map</code>","text":"<pre><code>from nirvana.ops import map\n\noutputs = map.map_wrapper(\n    input_data=df,\n    user_instruction=\"Extract genre\",\n    input_column=\"overview\",\n    output_columns=[\"genre\"],\n    strategy=\"plain\"\n)\n</code></pre> <p>Returns: <code>MapOpOutputs</code> with: - <code>field_name</code>: List of output column names - <code>output</code>: Dictionary mapping column names to values - <code>cost</code>: Total token cost</p>"},{"location":"api_reference/#nirvanaopsfilter","title":"<code>nirvana.ops.filter</code>","text":"<pre><code>from nirvana.ops import filter\n\noutputs = filter.filter_wrapper(\n    input_data=df,\n    user_instruction=\"Rating &gt; 8.5\",\n    input_column=\"IMDB_Rating\",\n    strategy=\"plain\"\n)\n</code></pre> <p>Returns: <code>FilterOpOutputs</code> with: - <code>output</code>: List of boolean values - <code>cost</code>: Total token cost</p>"},{"location":"api_reference/#nirvanaopsreduce","title":"<code>nirvana.ops.reduce</code>","text":"<pre><code>from nirvana.ops import reduce\n\noutputs = reduce.reduce_wrapper(\n    input_data=df,\n    user_instruction=\"Count crime movies\",\n    input_column=\"genre\"\n)\n</code></pre> <p>Returns: <code>ReduceOpOutputs</code> with: - <code>output</code>: Aggregated result - <code>cost</code>: Total token cost</p>"},{"location":"api_reference/#nirvanaopsjoin","title":"<code>nirvana.ops.join</code>","text":"<pre><code>from nirvana.ops import join\n\noutputs = join.join_wrapper(\n    left_data=df1,\n    right_data=df2,\n    user_instruction=\"Do these match?\",\n    left_on=\"col1\",\n    right_on=\"col2\",\n    how=\"inner\"\n)\n</code></pre> <p>Returns: <code>JoinOpOutputs</code> with: - <code>joined_pairs</code>: List of (left_idx, right_idx) tuples - <code>left_join_keys</code>: List of left join keys - <code>right_join_keys</code>: List of right join keys - <code>cost</code>: Total token cost</p>"},{"location":"api_reference/#query-optimization","title":"Query Optimization","text":""},{"location":"api_reference/#nirvanaoptimoptimizeconfig","title":"<code>nirvana.optim.OptimizeConfig</code>","text":"<p>Configuration class for query optimization.</p>"},{"location":"api_reference/#constructor_1","title":"Constructor","text":"<pre><code>OptimizeConfig(\n    do_logical_optimization: bool = True,\n    do_physical_optimization: bool = True,\n    sample_ratio: Optional[float] = None,\n    sample_size: Optional[int] = None,\n    improve_margin: float = 0.2,\n    approx_mode: bool = True,\n    filter_pullup: bool = True,\n    filter_pushdown: bool = True,\n    map_pullup: bool = True,\n    non_llm_pushdown: bool = True,\n    non_llm_replace: bool = True,\n    avaiable_models: list[str] = []\n)\n</code></pre> <p>Parameters:</p> <p>Optimization Flags: - <code>do_logical_optimization</code> (bool): Enable logical plan optimization (default: True) - <code>do_physical_optimization</code> (bool): Enable physical plan optimization (default: True)</p> <p>Physical Optimization: - <code>sample_ratio</code> (float, optional): Ratio of data for optimization (0.0-1.0) - <code>sample_size</code> (int, optional): Number of samples for optimization - <code>improve_margin</code> (float): Minimum improvement threshold (default: 0.2) - <code>approx_mode</code> (bool): Use approximation mode (default: True) - <code>avaiable_models</code> (list[str]): Available models for selection</p> <p>Logical Optimization Rules: - <code>filter_pullup</code> (bool): Enable filter pullup (default: True) - <code>filter_pushdown</code> (bool): Enable filter pushdown (default: True) - <code>map_pullup</code> (bool): Enable map pullup (default: True) - <code>non_llm_pushdown</code> (bool): Enable non-LLM pushdown (default: True) - <code>non_llm_replace</code> (bool): Enable non-LLM replacement (default: True)</p> <p>Example: <pre><code>config = nv.optim.OptimizeConfig(\n    do_logical_optimization=True,\n    do_physical_optimization=True,\n    sample_size=10,\n    improve_margin=0.15,\n    non_llm_replace=False  # Disable specific rule\n)\n</code></pre></p>"},{"location":"api_reference/#nirvanaoptimplanoptimizer","title":"<code>nirvana.optim.PlanOptimizer</code>","text":"<p>Plan optimizer class (typically used internally).</p>"},{"location":"api_reference/#methods","title":"Methods","text":""},{"location":"api_reference/#optimize_logical_planplan-lineagenode-lineagenode","title":"<code>optimize_logical_plan(plan: LineageNode) -&gt; LineageNode</code>","text":"<p>Optimize the logical plan.</p> <p>Parameters: - <code>plan</code> (LineageNode): Root node of the lineage graph</p> <p>Returns: - <code>LineageNode</code>: Optimized plan</p>"},{"location":"api_reference/#optimize_physical_planplan-lineagenode-num_records-int-tuple","title":"<code>optimize_physical_plan(plan: LineageNode, num_records: int) -&gt; tuple</code>","text":"<p>Optimize the physical plan.</p> <p>Parameters: - <code>plan</code> (LineageNode): Root node of the lineage graph - <code>num_records</code> (int): Number of records in the dataset</p> <p>Returns: - <code>tuple</code>: (output DataFrame, cost, runtime)</p>"},{"location":"api_reference/#configuration","title":"Configuration","text":""},{"location":"api_reference/#nirvanaconfigure_llm_backbone","title":"<code>nirvana.configure_llm_backbone</code>","text":"<p>Configure the LLM backend for all operations.</p> <pre><code>nirvana.configure_llm_backbone(\n    model_name: str = None,\n    api_key: Union[str, Path] = None,\n    base_url: str = None,\n    **kwargs\n)\n</code></pre> <p>Parameters: - <code>model_name</code> (str): Model name (e.g., \"gpt-4o\", \"deepseek-chat\") - <code>api_key</code> (str | Path): API key or path to API key file - <code>base_url</code> (str, optional): Base URL (inferred from model_name if not provided) - <code>**kwargs</code>: Additional arguments for LLMClient</p> <p>Example: <pre><code>import nirvana as nv\n\nnv.configure_llm_backbone(\n    model_name=\"gpt-4o\",\n    api_key=\"sk-...\",\n    max_tokens=512,\n    temperature=0.1\n)\n</code></pre></p>"},{"location":"api_reference/#data-types","title":"Data Types","text":""},{"location":"api_reference/#nirvanaimagearray","title":"<code>nirvana.ImageArray</code>","text":"<p>Array type for image data.</p> <pre><code>from nirvana import ImageArray\n\nimages = ImageArray([\n    \"https://example.com/image1.png\",\n    \"/path/to/image2.jpg\"\n])\n</code></pre>"},{"location":"api_reference/#nirvanaimagedtype","title":"<code>nirvana.ImageDtype</code>","text":"<p>Pandas extension dtype for images.</p> <pre><code>from nirvana import ImageDtype\n\n# Automatically registered with pandas\ndf = pd.DataFrame({\n    \"images\": ImageArray([...])\n})\n</code></pre>"},{"location":"api_reference/#internal-classes","title":"Internal Classes","text":""},{"location":"api_reference/#nirvanalineagelineagenode","title":"<code>nirvana.lineage.LineageNode</code>","text":"<p>Represents a node in the data lineage graph.</p> <p>Properties: - <code>op_name</code>: Operator name - <code>operator</code>: Operator instance - <code>node_fields</code>: Field metadata - <code>left_child</code>: Left child node - <code>right_child</code>: Right child node</p> <p>Methods: - <code>execute_operation(input)</code>: Execute the operation - <code>run(input)</code>: Run and return NodeOutput</p>"},{"location":"api_reference/#nirvanaopsbasebaseoperation","title":"<code>nirvana.ops.base.BaseOperation</code>","text":"<p>Base class for all operators.</p> <p>Properties: - <code>op_name</code>: Operator name - <code>user_instruction</code>: Natural language instruction - <code>model</code>: LLM model to use - <code>implementation</code>: Implementation strategy</p> <p>Methods: - <code>execute(input_data, **kwargs)</code>: Abstract method to execute the operation</p>"},{"location":"development/","title":"Development","text":"<p>This section covers core concepts and internals of Nirvana for developers who want to understand or extend the framework.</p>"},{"location":"development/#data-lineage","title":"Data Lineage","text":"<p>Data lineage is the core abstraction in Nirvana that enables lazy execution, query optimization, and cost tracking.</p>"},{"location":"development/#overview","title":"Overview","text":"<p>Data lineage is represented as a directed acyclic graph (DAG) where: - Nodes represent operators (scan, map, filter, join, reduce, rank) - Edges represent data flow between operators - Each node tracks input/output fields and dependencies</p>"},{"location":"development/#lineagenode","title":"LineageNode","text":"<p>The <code>LineageNode</code> class (in <code>nirvana/lineage/abstractions.py</code>) is the fundamental building block:</p> <pre><code>class LineageNode(NodeBase):\n    def __init__(\n        self,\n        op_name: str,\n        op_kwargs: dict,\n        node_fields: dict,\n        datasource: pd.DataFrame | None = None,\n        **kwargs\n    ):\n        self.operator = op_mapping[op_name](**op_kwargs)\n        self.node_fields = NodeFields(**node_fields)\n        self.datasource = datasource\n        self._left_child = None\n        self._right_child = None\n</code></pre> <p>Key Components:</p> <ol> <li>Operator: The actual operation instance (MapOperation, FilterOperation, etc.)</li> <li>NodeFields: Tracks input and output fields:    <pre><code>@dataclass\nclass NodeFields:\n    left_input_fields: list[str]\n    right_input_fields: list[str]\n    output_fields: list[str]\n</code></pre></li> <li>Child Nodes: Left and right children for binary operations (e.g., join)</li> </ol>"},{"location":"development/#building-lineage","title":"Building Lineage","text":"<p>When you call semantic operations on a DataFrame, nodes are added to the lineage:</p> <pre><code>df = nv.DataFrame(data)\n\n# Creates a scan node\ndf.initialize()  # Called automatically in __init__\n\n# Adds a map node\ndf.semantic_map(...)  # Creates LineageNode with MapOperation\n\n# Adds a filter node\ndf.semantic_filter(...)  # Creates LineageNode with FilterOperation\n</code></pre> <p>The <code>LineageMixin</code> (in <code>nirvana/lineage/mixin.py</code>) provides the lineage management:</p> <pre><code>class LineageMixin:\n    def initialize(self):\n        # Create scan node\n        node = LineageNode(\n            op_name=\"scan\",\n            op_kwargs={\"source\": \"dataframe\", \"output_columns\": self.columns},\n            node_fields={\"left_input_fields\": [], \"right_input_fields\": [], \"output_fields\": self.columns},\n            datasource=self._data\n        )\n        self.leaf_node = node\n\n    def add_operator(self, op_name: str, op_kwargs: dict, data_kwargs: dict, **kwargs):\n        node = LineageNode(op_name, op_kwargs=op_kwargs, node_fields=data_kwargs)\n        if op_name == \"join\":\n            node.set_left_child(self.leaf_node)\n            node.set_right_child(kwargs[\"other\"].leaf_node)\n        else:\n            node.set_left_child(self.leaf_node)\n        self.leaf_node = node\n</code></pre>"},{"location":"development/#execution-model","title":"Execution Model","text":"<p>Execution follows a post-order traversal of the lineage graph:</p> <pre><code>def execute_along_lineage(leaf_node: LineageNode):\n    def _execute_node(node: LineageNode) -&gt; pd.DataFrame:\n        # Recursively execute children first\n        if node.left_child:\n            left_output = _execute_node(node.left_child)\n        if node.right_child:\n            right_output = _execute_node(node.right_child)\n\n        # Execute current node\n        if node.op_name == \"scan\":\n            return node.datasource\n        elif node.op_name == \"join\":\n            return node.run([left_output, right_output])\n        else:\n            return node.run(left_output)\n\n    return _execute_node(leaf_node)\n</code></pre> <p>Execution Flow:</p> <ol> <li>Scan: Returns the datasource DataFrame</li> <li>Unary Operations (map, filter, reduce): Execute on left child output</li> <li>Binary Operations (join): Execute on both children's outputs</li> </ol>"},{"location":"development/#node-execution","title":"Node Execution","text":"<p>Each <code>LineageNode</code> has a <code>run()</code> method that:</p> <ol> <li>Executes the operator's <code>execute()</code> method</li> <li>Collates the results into a DataFrame</li> <li>Returns a <code>NodeOutput</code> with the result, cost, and metadata</li> </ol> <pre><code>async def run(self, input: pd.DataFrame | list[pd.DataFrame] | None = None) -&gt; NodeOutput:\n    if self.op_name == \"scan\":\n        return NodeOutput(output=self.datasource, cost=0.0)\n\n    elif self.op_name == \"join\":\n        op_outputs = await self.operator.execute(left_data=input[0], right_data=input[1])\n        # Collate join results\n        input[0][\"keys\"] = op_outputs.left_join_keys\n        input[1][\"keys\"] = op_outputs.right_join_keys\n        output = input[0].join(input[1], on=\"keys\", how=self.operator.how).drop(\"keys\", axis=1)\n        return NodeOutput(output=output, cost=op_outputs.cost)\n\n    elif self.op_name == \"filter\":\n        op_outputs = await self.operator.execute(input_data=input)\n        if op_outputs.output is None:\n            return NodeOutput(output=input, cost=op_outputs.cost)\n        return NodeOutput(output=input[op_outputs.output], cost=op_outputs.cost)\n\n    # ... other operators\n</code></pre>"},{"location":"development/#operators","title":"Operators","text":""},{"location":"development/#baseoperation","title":"BaseOperation","text":"<p>All operators inherit from <code>BaseOperation</code> (in <code>nirvana/ops/base.py</code>):</p> <pre><code>class BaseOperation(ABC):\n    llm: LLMClient = None  # Shared LLM client\n\n    def __init__(\n        self,\n        op_name: str,\n        user_instruction: str = \"\",\n        context: list[dict] | str | None = None,\n        model: str | None = None,\n        tool: BaseTool | None = None,\n        implementation: str | None = \"plain\",\n        rate_limit: int = 16,\n        assertions: list[Callable] | None = [],\n    ):\n        self.op_name = op_name\n        self.user_instruction = user_instruction\n        self.model = model if model else self.llm.default_model\n        self.semaphore = asyncio.Semaphore(rate_limit)\n        # ...\n\n    @abstractmethod\n    def execute(self, *args, **kwargs):\n        raise NotImplementedError\n</code></pre> <p>Key Features:</p> <ul> <li>Shared LLM Client: All operations use the same <code>LLMClient</code> instance</li> <li>Rate Limiting: Semaphore controls concurrent LLM calls</li> <li>Implementation Strategies: Support for different execution strategies</li> <li>Tool Support: Can use Python functions instead of LLM calls</li> </ul>"},{"location":"development/#operator-structure","title":"Operator Structure","text":"<p>Each operator follows this pattern:</p> <ol> <li> <p>Output Class: Dataclass defining the output structure    <pre><code>@dataclass\nclass MapOpOutputs(BaseOpOutputs):\n    field_name: list[str] | None\n    output: dict[str, Iterable]\n    cost: float\n</code></pre></p> </li> <li> <p>Operation Class: Implements the operator logic    <pre><code>class MapOperation(BaseOperation):\n    def __init__(self, user_instruction, input_columns, output_columns, **kwargs):\n        super().__init__(op_name=\"map\", user_instruction=user_instruction, **kwargs)\n        self.input_columns = input_columns\n        self.output_columns = output_columns\n\n    async def execute(self, input_data: pd.DataFrame, **kwargs) -&gt; MapOpOutputs:\n        # Implementation\n</code></pre></p> </li> <li> <p>Wrapper Function: Convenience function for direct usage    <pre><code>def map_wrapper(input_data, user_instruction, input_column, output_columns, **kwargs):\n    map_op = MapOperation(...)\n    return asyncio.run(map_op.execute(input_data=input_data, **kwargs))\n</code></pre></p> </li> </ol>"},{"location":"development/#implementation-strategies","title":"Implementation Strategies","text":"<p>Operators support different implementation strategies:</p> <ul> <li>plain: Direct LLM call</li> <li>self-refine: Generate, evaluate, refine if needed</li> <li>fewshot: In-context learning with examples</li> <li>vote: Multiple LLM calls with voting (for some operators)</li> </ul> <p>Example from <code>MapOperation</code>:</p> <pre><code>if self.implementation == \"plain\":\n    execution_func = functools.partial(self._execute_by_plain_llm, ...)\nelif self.implementation == \"self_refine\":\n    execution_func = functools.partial(self._execute_by_self_refine, ...)\nelif self.implementation == \"fewshot\":\n    execution_func = functools.partial(self._execute_by_fewshot_llm, ...)\n</code></pre>"},{"location":"development/#query-optimization","title":"Query Optimization","text":""},{"location":"development/#logical-optimization","title":"Logical Optimization","text":"<p>Logical optimization applies rule-based transformations to the lineage graph.</p> <p>Optimization Rules (in <code>nirvana/optim/rules/</code>):</p> <ol> <li>NonLLMReplace: Replaces LLM calls with UDFs when possible</li> <li>MapPullup: Moves map operations up in the plan</li> <li>FilterPullup: Moves filters to earlier positions</li> <li>FilterPushdown: Pushes filters down and duplicates over equivalency sets</li> <li>NonLLMPushdown: Pushes non-LLM operations down</li> </ol> <p>Rule Application:</p> <pre><code>class LogicalOptimizer:\n    def optimize(self, plan: LineageNode):\n        plan = NonLLMReplace.transform(plan) if self.non_llm_replace else plan\n        plan = MapPullup.transform(plan) if self.map_pullup else plan\n        plan = FilterPullup.transform(plan) if self.filter_pullup else plan\n        plan = FilterPushdown.transform(plan) if self.filter_pushdown else plan\n        plan = NonLLMPushdown.transform(plan) if self.non_llm_pushdown else plan\n        return plan\n</code></pre> <p>Each rule implements a <code>transform()</code> method that takes a <code>LineageNode</code> and returns a transformed <code>LineageNode</code>.</p>"},{"location":"development/#physical-optimization","title":"Physical Optimization","text":"<p>Physical optimization selects the best LLM model for each operator based on cost and quality.</p> <p>Process:</p> <ol> <li>Sample Data: Use a subset of data for testing</li> <li>Test Models: Try different models on the sample</li> <li>Evaluate: Compare cost and quality</li> <li>Select: Choose model that meets improvement threshold</li> <li>Execute: Run on full dataset with selected model</li> </ol> <pre><code>class PhysicalOptimizer:\n    async def optimize_exec_model(\n        self,\n        node: LineageNode,\n        input_data: pd.DataFrame,\n        num_samples: int,\n        improve_margin: float = 0.2\n    ):\n        # Split data into sample and test set\n        sample_data, test_set = self.split_input_data(node.op_name, input_data, num_samples)\n\n        # Test default model\n        default_output = await node.execute_operation(sample_data)\n        default_cost = default_output.cost\n\n        # Try alternative models\n        best_model = node.operator.model\n        for model in self.available_models:\n            node.operator.model = model\n            test_output = await node.execute_operation(sample_data)\n            if test_output.cost &lt; default_cost * (1 - improve_margin):\n                best_model = model\n                break\n\n        # Set best model and execute on full dataset\n        node.set_exec_model(best_model)\n        return await node.execute_operation(input_data)\n</code></pre>"},{"location":"development/#llm-backbone","title":"LLM Backbone","text":""},{"location":"development/#llmclient","title":"LLMClient","text":"<p>The <code>LLMClient</code> (in <code>nirvana/executors/llm_backbone.py</code>) manages LLM interactions:</p> <pre><code>class LLMClient:\n    default_model: str | None = None\n    client = None\n    config: LLMArguments = LLMArguments()\n\n    @classmethod\n    def configure(cls, model_name: str, api_key: str | Path | None = None, **kwargs):\n        # Configure provider based on model name\n        api_key, base_url = _get_openai_compatible_provider_info(model_name, api_key)\n        cls.client = _create_client(api_key=api_key, base_url=base_url, **kwargs)\n        cls.default_model = model_name\n        return cls()\n\n    async def __call__(self, messages: list[dict], parse_tags: bool = False, **kwargs):\n        # Make LLM call\n        response = await self.client.responses.create(...)\n        # Parse output\n        # Return dict with output and cost\n</code></pre> <p>Features:</p> <ul> <li>Provider Inference: Automatically detects provider from model name</li> <li>Cost Tracking: Computes token costs based on model pricing</li> <li>Output Parsing: Supports XML tag parsing and code extraction</li> <li>Retry Logic: Handles timeouts with configurable retries</li> </ul>"},{"location":"development/#cost-computation","title":"Cost Computation","text":"<p>Cost is computed based on model pricing:</p> <pre><code>def _compute_usage(self, response):\n    model_name = response.model\n    input_tokens = response.usage.input_tokens\n    output_tokens = response.usage.output_tokens\n    cached_tokens = response.usage.input_tokens_details.cached_tokens\n\n    pricing = MODEL_PRICING[model_name]\n\n    if model_name.startswith(\"qwen\"):\n        # Qwen: no cache pricing difference\n        input_cost = (input_tokens / 1000) * pricing[\"Input\"]\n        output_cost = (output_tokens / 1000) * pricing[\"Output\"]\n    else:\n        # Other providers: separate cache pricing\n        input_cost = (input_tokens - cached_tokens) / 1000 * pricing[\"Input\"]\n        cache_cost = (cached_tokens / 1000) * pricing[\"Cache\"]\n        output_cost = (output_tokens / 1000) * pricing[\"Output\"]\n\n    return input_cost + output_cost + cache_cost\n</code></pre>"},{"location":"development/#extending-nirvana","title":"Extending Nirvana","text":""},{"location":"development/#adding-a-new-operator","title":"Adding a New Operator","text":"<ol> <li> <p>Create Output Class:    <pre><code>@dataclass\nclass MyOpOutputs(BaseOpOutputs):\n    result: Any\n    cost: float\n</code></pre></p> </li> <li> <p>Implement Operation Class:    <pre><code>class MyOperation(BaseOperation):\n    def __init__(self, user_instruction, **kwargs):\n        super().__init__(op_name=\"myop\", user_instruction=user_instruction, **kwargs)\n\n    async def execute(self, input_data: pd.DataFrame, **kwargs) -&gt; MyOpOutputs:\n        # Implementation\n        return MyOpOutputs(result=..., cost=...)\n</code></pre></p> </li> <li> <p>Register in op_mapping:    <pre><code># In nirvana/lineage/abstractions.py\nop_mapping = {\n    # ... existing operators\n    \"myop\": MyOperation,\n}\n</code></pre></p> </li> <li> <p>Add to DataFrame:    <pre><code># In nirvana/dataframe/frame.py\ndef semantic_myop(self, user_instruction, input_column, **kwargs):\n    op_kwargs = {\"user_instruction\": user_instruction, ...}\n    data_kwargs = {...}\n    self.add_operator(op_name=\"myop\", op_kwargs=op_kwargs, data_kwargs=data_kwargs)\n</code></pre></p> </li> </ol>"},{"location":"development/#adding-an-optimization-rule","title":"Adding an Optimization Rule","text":"<ol> <li> <p>Create Rule Class:    <pre><code>class MyRule:\n    @staticmethod\n    def transform(plan: LineageNode) -&gt; LineageNode:\n        # Transform the plan\n        return transformed_plan\n</code></pre></p> </li> <li> <p>Add to LogicalOptimizer:    <pre><code># In nirvana/optim/logical.py\ndef optimize(self, plan: LineageNode):\n    plan = MyRule.transform(plan) if self.my_rule else plan\n    # ... other rules\n    return plan\n</code></pre></p> </li> <li> <p>Add Config Option:    <pre><code># In nirvana/optim/optimizer.py\nclass OptimizeConfig(BaseModel):\n    my_rule: bool = Field(default=True, description=\"Enable my rule\")\n</code></pre></p> </li> </ol>"},{"location":"development/#architecture-overview","title":"Architecture Overview","text":"<pre><code>nirvana/\n\u251c\u2500\u2500 dataframe/          # DataFrame and data types\n\u2502   \u251c\u2500\u2500 frame.py        # DataFrame class\n\u2502   \u251c\u2500\u2500 arrays/         # Custom array types (Image, Audio, etc.)\n\u2502   \u2514\u2500\u2500 elements/       # Schema and field definitions\n\u251c\u2500\u2500 ops/                # Semantic operators\n\u2502   \u251c\u2500\u2500 base.py         # BaseOperation\n\u2502   \u251c\u2500\u2500 map.py          # Map operator\n\u2502   \u251c\u2500\u2500 filter.py       # Filter operator\n\u2502   \u251c\u2500\u2500 join.py         # Join operator\n\u2502   \u251c\u2500\u2500 reduce.py       # Reduce operator\n\u2502   \u2514\u2500\u2500 prompt_templates/  # LLM prompts for each operator\n\u251c\u2500\u2500 lineage/            # Data lineage\n\u2502   \u251c\u2500\u2500 abstractions.py # LineageNode, NodeFields\n\u2502   \u2514\u2500\u2500 mixin.py        # LineageMixin for DataFrame\n\u251c\u2500\u2500 optim/              # Query optimization\n\u2502   \u251c\u2500\u2500 optimizer.py    # PlanOptimizer, OptimizeConfig\n\u2502   \u251c\u2500\u2500 logical.py      # LogicalOptimizer\n\u2502   \u251c\u2500\u2500 physical.py     # PhysicalOptimizer\n\u2502   \u2514\u2500\u2500 rules/          # Optimization rules\n\u2514\u2500\u2500 executors/          # LLM execution\n    \u251c\u2500\u2500 llm_backbone.py # LLMClient\n    \u2514\u2500\u2500 constants.py    # Model pricing, etc.\n</code></pre>"},{"location":"development/#best-practices-for-developers","title":"Best Practices for Developers","text":"<ol> <li>Async Operations: All LLM calls are async - use <code>asyncio.run()</code> or <code>await</code> appropriately</li> <li>Cost Tracking: Always track and return costs in operator outputs</li> <li>Error Handling: Handle LLM failures gracefully with fallbacks</li> <li>Rate Limiting: Use semaphores to control concurrent LLM calls</li> <li>Type Hints: Use type hints for better IDE support and documentation</li> </ol>"},{"location":"get_started/","title":"Get Started","text":"<p>Nirvana is an LLM-powered semantic data analytics programming framework that enables natural language queries over structured and unstructured data.</p>"},{"location":"get_started/#installation","title":"Installation","text":"<p>Install Nirvana from PyPI:</p> <pre><code>pip install nirvana-ai\n</code></pre> <p>Or install the latest version from the main branch:</p> <pre><code>pip install git+https://github.com/JunHao-Zhu/nirvana.git\n</code></pre>"},{"location":"get_started/#quick-start","title":"Quick Start","text":""},{"location":"get_started/#1-configure-the-llm-backbone","title":"1. Configure the LLM Backbone","text":"<p>Before using semantic operators, configure the LLM settings:</p> <pre><code>import nirvana as nv\n\nnv.configure_llm_backbone(\n    model_name=\"gpt-4o\",\n    api_key=\"&lt;Your API Key&gt;\",\n    base_url=None  # Optional, inferred from model_name\n)\n</code></pre> <p>Supported model prefixes: - <code>gpt-*</code> or <code>text-embedding-*</code>: OpenAI (defaults to <code>OPENAI_API_KEY</code>) - <code>deepseek-*</code>: DeepSeek (defaults to <code>DEEPSEEK_API_KEY</code>) - <code>qwen-*</code>: Qwen (defaults to <code>QWEN_API_KEY</code>) - <code>gemini-*</code>: Gemini (defaults to <code>GEMINI_API_KEY</code>)</p>"},{"location":"get_started/#2-create-a-dataframe","title":"2. Create a DataFrame","text":"<p>Nirvana's <code>DataFrame</code> extends pandas DataFrame with support for unstructured data types (images, text, audio):</p> <pre><code>import pandas as pd\nimport nirvana as nv\n\n# Create from a pandas DataFrame\ndf = pd.DataFrame({\n    \"title\": [\"The Godfather\", \"The Dark Knight\"],\n    \"overview\": [\n        \"An organized crime dynasty's aging patriarch transfers control...\",\n        \"When the menace known as the Joker wreaks havoc...\"\n    ]\n})\ndf = nv.DataFrame(df)\n\n# Or load from a file\ndf = nv.DataFrame.from_external_file(\"movie_data.csv\")\n</code></pre>"},{"location":"get_started/#3-apply-semantic-operations","title":"3. Apply Semantic Operations","text":"<p>Build a query using semantic operators:</p> <pre><code># Extract genre from movie overviews\ndf.semantic_map(\n    user_instruction=\"According to the movie overview, extract the genre of each movie.\",\n    input_column=\"overview\",\n    output_column=\"genre\"\n)\n\n# Filter movies with high ratings\ndf.semantic_filter(\n    user_instruction=\"The rating is higher than 8.5.\",\n    input_column=\"IMDB_Rating\"\n)\n\n# Aggregate results\ndf.semantic_reduce(\n    user_instruction=\"Count the number of crime movies.\",\n    input_column=\"genre\"\n)\n</code></pre>"},{"location":"get_started/#4-optimize-and-execute","title":"4. Optimize and Execute","text":"<p>Optimize the query plan and execute:</p> <pre><code># Configure optimization\nconfig = nv.optim.OptimizeConfig(\n    do_logical_optimization=True,\n    do_physical_optimization=True,\n    sample_size=5,\n    improve_margin=0.2\n)\n\n# Execute with optimization\noutput, cost, runtime = df.optimize_and_execute(optim_config=config)\n\nprint(f\"Output: {output}\")\nprint(f\"Cost: ${cost:.4f}\")\nprint(f\"Runtime: {runtime:.2f}s\")\n</code></pre>"},{"location":"get_started/#whats-next","title":"What's Next?","text":"<ul> <li>Learn about semantic operators in detail</li> <li>Explore query optimization features</li> <li>Understand data lineage concepts</li> <li>Check the API reference for detailed documentation</li> </ul>"},{"location":"tutorial/","title":"Tutorial","text":"<p>This tutorial covers the core concepts and features of Nirvana, from basic operations to advanced query optimization.</p>"},{"location":"tutorial/#dataframe","title":"DataFrame","text":"<p>Nirvana's <code>DataFrame</code> is built on pandas DataFrame and adds support for unstructured data types and semantic operations.</p>"},{"location":"tutorial/#creating-dataframes","title":"Creating DataFrames","text":"<pre><code>import pandas as pd\nimport nirvana as nv\n\n# From pandas DataFrame\ndf = nv.DataFrame(pd.DataFrame({\"col1\": [1, 2, 3], \"col2\": [\"a\", \"b\", \"c\"]}))\n\n# From external file\ndf = nv.DataFrame.from_external_file(\"data.csv\", sep=\",\")\n\n# With image data\nlogo_imgs = nv.ImageArray([\n    \"https://spark.apache.org/images/spark-logo.png\",\n    \"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c6/PyTorch_logo_black.svg/488px-PyTorch_logo_black.svg.png\"\n])\ndf = nv.DataFrame(pd.DataFrame({\n    \"names\": [\"Spark\", \"Pytorch\"],\n    \"logos\": logo_imgs\n}))\n</code></pre>"},{"location":"tutorial/#dataframe-properties","title":"DataFrame Properties","text":"<pre><code># Access columns\nprint(df.columns)  # ['col1', 'col2']\n\n# Get number of rows\nprint(len(df))  # 3\n\n# Check column membership\nprint(\"col1\" in df)  # True\n</code></pre>"},{"location":"tutorial/#operators","title":"Operators","text":"<p>Nirvana provides semantic operators that use LLMs to process data based on natural language instructions.</p>"},{"location":"tutorial/#map-operator","title":"Map Operator","text":"<p>The <code>map</code> operator performs element-wise transformations, creating new columns based on natural language instructions.</p> <pre><code>df = nv.DataFrame(pd.DataFrame({\n    \"title\": [\"The Godfather\", \"The Dark Knight\"],\n    \"overview\": [\n        \"An organized crime dynasty's aging patriarch transfers control...\",\n        \"When the menace known as the Joker wreaks havoc...\"\n    ]\n}))\n\n# Extract genre from overview\ndf.semantic_map(\n    user_instruction=\"According to the movie overview, extract the genre of each movie.\",\n    input_column=\"overview\",\n    output_column=\"genre\"\n)\n</code></pre> <p>Implementation Strategies: - <code>plain</code>: Direct LLM call (default) - <code>self-refine</code>: Generate, evaluate, and refine if needed - <code>fewshot</code>: Use in-context learning with examples</p>"},{"location":"tutorial/#filter-operator","title":"Filter Operator","text":"<p>The <code>filter</code> operator evaluates conditions on each row, returning boolean values.</p> <pre><code># Filter movies released after 2000\ndf.semantic_filter(\n    user_instruction=\"Whether the movie is released after 2000?\",\n    input_column=\"title\"\n)\n\n# Filter by rating\ndf.semantic_filter(\n    user_instruction=\"The rating is higher than 8.5.\",\n    input_column=\"IMDB_Rating\"\n)\n</code></pre>"},{"location":"tutorial/#reduce-operator","title":"Reduce Operator","text":"<p>The <code>reduce</code> operator aggregates values in a column into a single result.</p> <pre><code># Find common themes\ndf.semantic_reduce(\n    user_instruction=\"Based on the overviews, provide several common points of these movies.\",\n    input_column=\"overview\"\n)\n\n# Count specific items\ndf.semantic_reduce(\n    user_instruction=\"Count the number of crime movies.\",\n    input_column=\"genre\"\n)\n</code></pre> <p>Note: The current implementation is simple. Future versions will support optimizations like \"summarize and aggregate\" and \"incremental aggregation.\"</p>"},{"location":"tutorial/#join-operator","title":"Join Operator","text":"<p>The <code>join</code> operator joins two DataFrames based on semantic similarity between columns.</p> <pre><code># Clinical notes\nclinical_note = nv.DataFrame(pd.DataFrame({\n    \"name\": [\"Alice\", \"Bob\"],\n    \"age\": [12, 20],\n    \"gender\": [\"F\", \"M\"],\n    \"symptom\": [\"headache\", \"have a cough\"]\n}))\n\n# Drug database\ndrug = nv.DataFrame(pd.DataFrame({\n    \"name\": [\"Salbutamol\", \"ibuprofen\"],\n    \"medical_use\": [\n        \"treat bronchospasm, as well as chronic obstructive pulmonary disease\",\n        \"treat mild to moderate pain, painful menstruation, osteoarthritis, dental pain, headaches, and pain from kidney stones\"\n    ]\n}))\n\n# Semantic join\nclinical_note.semantic_join(\n    other=drug,\n    user_instruction=\"Does the drug cure the possible disease according to the symptoms?\",\n    left_on=\"symptom\",\n    right_on=\"medical_use\",\n    how=\"inner\"  # or \"left\", \"right\"\n)\n</code></pre> <p>Join Types: - <code>inner</code>: Keep only matching pairs - <code>left</code>: Keep all left rows, match with right where possible - <code>right</code>: Keep all right rows, match with left where possible</p> <p>Note: The current implementation has quadratic complexity. Optimizations are planned.</p>"},{"location":"tutorial/#rank-operator","title":"Rank Operator","text":"<p>The <code>rank</code> operator ranks rows based on a natural language criterion.</p> <pre><code>df.semantic_rank(\n    user_instruction=\"rank the movies by their relevance to DC Comics.\",\n    input_column=\"title\"\n)\n</code></pre>"},{"location":"tutorial/#plan-optimization","title":"Plan Optimization","text":"<p>Nirvana supports two levels of query optimization: logical and physical plan optimization.</p>"},{"location":"tutorial/#logical-plan-optimization","title":"Logical Plan Optimization","text":"<p>Logical optimization applies rule-based transformations to improve query efficiency:</p> <pre><code>df = nv.DataFrame(pd.read_csv(\"movie_data.csv\"))\n\n# Build a query\ndf.semantic_map(\n    user_instruction=\"According to the movie overview, extract the genre of each movie.\",\n    input_column=\"Overview\",\n    output_column=\"Genre\"\n)\ndf.semantic_filter(\n    user_instruction=\"The rating is higher than 7.\",\n    input_column=\"IMDB_Rating\"\n)\ndf.semantic_filter(\n    user_instruction=\"The rating is lower than 8.\",\n    input_column=\"IMDB_Rating\"\n)\ndf.semantic_reduce(\n    user_instruction=\"Count the number of crime movies.\",\n    input_column=\"Genre\"\n)\n\n# View the logical plan\ndf.print_lineage_graph()\n\n# Optimize and execute\nconfig = nv.optim.OptimizeConfig(\n    do_logical_optimization=True,\n    do_physical_optimization=False\n)\noutput, cost, runtime = df.optimize_and_execute(optim_config=config)\n</code></pre> <p>Transformation Rules:</p> <ol> <li> <p>Non-LLM Replacement: Replaces NL instructions over non-image/video/audio data with equivalent compute functions when possible.</p> </li> <li> <p>Map Pullup: Moves map operations to the top of the query plan when beneficial.</p> </li> <li> <p>Filter Pullup: Identifies cases where a filter can be applied on columns in other tables.</p> </li> <li> <p>Filter Pushdown: Pushes filters down into the query plan and duplicates filters over equivalency sets.</p> </li> <li> <p>Non-LLM Pushdown: Pushes operators using non-LLM functions/tools down into the query plan.</p> </li> </ol> <p>Configuring Rules:</p> <pre><code>config = nv.optim.OptimizeConfig(\n    do_logical_optimization=True,\n    non_llm_replace=True,      # Enable/disable specific rules\n    filter_pullup=True,\n    filter_pushdown=True,\n    map_pullup=True,\n    non_llm_pushdown=True\n)\n</code></pre>"},{"location":"tutorial/#physical-plan-optimization","title":"Physical Plan Optimization","text":"<p>Physical optimization selects the most cost-effective LLM model for each operator:</p> <pre><code>config = nv.optim.OptimizeConfig(\n    do_logical_optimization=True,\n    do_physical_optimization=True,\n    sample_size=5,              # Number of samples for optimization\n    improve_margin=0.2,         # Minimum improvement threshold\n    approx_mode=True,           # Use approximation mode\n    avaiable_models=[\"gpt-4o\", \"gpt-3.5-turbo\", \"deepseek-chat\"]\n)\n\noutput, cost, runtime = df.optimize_and_execute(optim_config=config)\n</code></pre> <p>Parameters: - <code>sample_size</code>: Number of data samples to use for model selection - <code>sample_ratio</code>: Alternative to <code>sample_size</code>, specifies ratio of data - <code>improve_margin</code>: Minimum cost improvement (0.0-1.0) to switch models - <code>approx_mode</code>: Whether to use approximation for faster optimization</p>"},{"location":"tutorial/#data-lineage","title":"Data Lineage","text":"<p>Every DataFrame operation builds a data lineage graph (DAG) that tracks: - Operator sequence - Input/output fields - Dependencies between operations</p> <pre><code># Build a query\ndf.semantic_map(...)\ndf.semantic_filter(...)\n\n# View the lineage graph\ndf.print_lineage_graph()\n\n# Execute along the lineage\noutput, cost, runtime = df.execute()\n</code></pre> <p>The lineage graph enables: - Lazy Execution: Operations are not executed until <code>execute()</code> or <code>optimize_and_execute()</code> is called - Plan Optimization: The optimizer can transform the graph - Cost Tracking: Track token costs for each operation</p>"},{"location":"tutorial/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Batch Operations: Use <code>rate_limit</code> to control concurrent LLM calls:    <pre><code>df.semantic_map(..., rate_limit=16)  # Max 16 concurrent calls\n</code></pre></p> </li> <li> <p>Use UDFs When Possible: For simple operations, provide Python functions instead of natural language:    <pre><code>df.semantic_filter(\n    user_instruction=\"Rating &gt; 8.5\",\n    input_column=\"rating\",\n    func=lambda x: x &gt; 8.5\n)\n</code></pre></p> </li> <li> <p>Optimize Selectively: Turn off optimization for simple queries:    <pre><code>config = nv.optim.OptimizeConfig(\n    do_logical_optimization=False,\n    do_physical_optimization=False\n)\n</code></pre></p> </li> <li> <p>Monitor Costs: Check the cost returned by <code>optimize_and_execute()</code>:    <pre><code>output, cost, runtime = df.optimize_and_execute()\nprint(f\"Total cost: ${cost:.4f}\")\n</code></pre></p> </li> </ol>"},{"location":"api/executor/llm/","title":"LLMs","text":"<p>Nirvana provides a unified interface for LLMs.</p>"},{"location":"api/executor/llm/#llmarguments","title":"LLMArguments","text":"<p>The LLMArguments class defines the arguments for LLMs.</p>"},{"location":"api/executor/llm/#llmclient","title":"LLMClient","text":"<p>The LLMClient is a unified interface for LLMs, which can be used to access different LLMs. Futhermore, it provides functionalities of LLM response parsing and token cost computation.</p>"},{"location":"api/executor/tools/","title":"Tools","text":""},{"location":"api/executor/tools/#functioncalltool","title":"FunctionCallTool","text":"<p>This is a tool that evaluates python code. It can be used to perform computations and relational operations.</p>"},{"location":"api/frame/dataframe/","title":"nirvana.DataFrame","text":""},{"location":"api/frame/dataframe/#class-dataframelineagemixin","title":"<code>class DataFrame(LineageMixin)</code>","text":"<p>A DataFrame class that extends pandas.DataFrame with semantic operations and data lineage tracking that enables lazy execution and query optimization.</p>"},{"location":"api/frame/dataframe/#constructor","title":"Constructor","text":"<pre><code>DataFrame(data: pd.DataFrame = None, *args, **kwargs)\n</code></pre> <p>Parameters:</p> <ul> <li><code>data</code> (pd.DataFrame): A pandas DataFrame to wrap</li> </ul> <p>Example: <pre><code>import pandas as pd\nimport nirvana as nv\n\ndf = nv.DataFrame(pd.DataFrame({\"col1\": [1, 2, 3]}))\n</code></pre></p>"},{"location":"api/frame/dataframe/#properties","title":"Properties","text":"<ul> <li><code>columns</code>: List of column names</li> <li><code>nrows</code>: Number of rows</li> <li><code>primary_key</code>: Primary key column (if set)</li> </ul>"},{"location":"api/frame/dataframe/#class-methods","title":"Class Methods","text":""},{"location":"api/frame/dataframe/#from_external_filepath-str-sep-kwargs","title":"<code>from_external_file(path: str, sep=',', **kwargs)</code>","text":"<p>Load a DataFrame from an external file.</p> <p>arguments:</p> <ul> <li><code>path</code> (str): Path to the file</li> <li><code>sep</code> (str): (default: ',') Delimiter</li> <li><code>**kwargs</code>: Additional arguments passed to <code>pd.read_table()</code></li> </ul> <p>Returns:</p> <ul> <li><code>DataFrame</code>: A new DataFrame instance</li> </ul>"},{"location":"api/frame/dataframe/#methods","title":"Methods","text":""},{"location":"api/frame/dataframe/#semantic_mapuser_instruction-str-input_column-str-output_column-str-rate_limit-int-16","title":"<code>semantic_map(user_instruction: str, input_column: str, output_column: str, rate_limit: int = 16)</code>","text":"<p>Add a map operation to the data lineage alongwith the dataframe.</p> <p>arguments:</p> <ul> <li><code>user_instruction</code> (str): Natural language instruction for the transformation</li> <li><code>input_column</code> (str): Column to transform</li> <li><code>output_column</code> (str): Name of the new column</li> <li><code>rate_limit</code> (int): Maximum concurrent LLM calls (default: 16)</li> </ul> <p>Example: <pre><code>df.semantic_map(\n    user_instruction=\"Extract the genre from the overview\",\n    input_column=\"overview\",\n    output_column=\"genre\"\n)\n</code></pre></p>"},{"location":"api/frame/dataframe/#semantic_filteruser_instruction-str-input_column-str-rate_limit-int-16","title":"<code>semantic_filter(user_instruction: str, input_column: str, rate_limit: int = 16)</code>","text":"<p>Add a filter operation to the data lineage alongwith the dataframe.</p> <p>arguments:</p> <ul> <li><code>user_instruction</code> (str): Natural language filtering condition</li> <li><code>input_column</code> (str): Column to evaluate</li> <li><code>rate_limit</code> (int): Maximum concurrent LLM calls (default: 16)</li> </ul> <p>Example: <pre><code>df.semantic_filter(\n    user_instruction=\"Whether the comment is positive\",\n    input_column=\"Comment\"\n)\n</code></pre></p>"},{"location":"api/frame/dataframe/#semantic_joinother-nirvanadataframe-user_instruction-str-left_on-str-right_on-str-how-str-rate_limit-int-16","title":"<code>semantic_join(other: nirvana.DataFrame, user_instruction: str, left_on: str, right_on: str, how: str, rate_limit: int = 16)</code>","text":"<p>Add a join operation to the data lineage alongwith the dataframe.</p> <p>arguments:</p> <ul> <li><code>other</code> (nirvana.DataFrame): Right DataFrame to join</li> <li><code>user_instruction</code> (str): Natural language join condition</li> <li><code>left_on</code> (str): Column from left DataFrame</li> <li><code>right_on</code> (str): Column from right DataFrame</li> <li><code>how</code> (str): Join type: \"inner\", \"left\", or \"right\"</li> <li><code>rate_limit</code> (int): Maximum concurrent LLM calls (default: 16)</li> </ul> <p>Example: <pre><code>symptom.semantic_join(\n    other=drug,\n    user_instruction=\"Does the drug cure the symptom?\",\n    left_on=\"symptom\",\n    right_on=\"medical_use\",\n    how=\"inner\"\n)\n</code></pre></p>"},{"location":"api/frame/dataframe/#semantic_rankuser_instruction-str-input_column-str-descend-bool-true-rate_limit-int-16","title":"<code>semantic_rank(user_instruction: str, input_column: str, descend: bool = True, rate_limit: int = 16)</code>","text":"<p>Add a rank operation to the data lineage alongwith the dataframe.</p> <p>arguments:</p> <ul> <li><code>user_instruction</code> (str): Natural language join condition</li> <li><code>input_column</code> (str): Column to evaluate</li> <li><code>descend</code> (bool): if <code>descend=True</code>, sort records from the most-satisfied to the least-satisfied; otherwise, sort them from the least-satisfied to the most-satisfied (default: <code>True</code>)</li> <li><code>rate_limit</code> (int): Maximum concurrent LLM calls (default: 16)</li> </ul> <p>Example: <pre><code>course.semantic_rank(\n    user_instruction=\"The course requires the least math\",\n    input_column=\"Courses\",\n    descend=True,\n)\n</code></pre></p>"},{"location":"api/frame/dataframe/#semantic_reduceuser_instruction-str-input_column-str-rate_limit-int-16","title":"<code>semantic_reduce(user_instruction: str, input_column: str, rate_limit: int = 16)</code>","text":"<p>Add an aggregation operation to the data lineage alongwith the dataframe.</p> <p>arguments:</p> <ul> <li><code>user_instruction</code> (str): Natural language aggregation instruction</li> <li><code>input_column</code> (str): Column to aggregate</li> <li><code>rate_limit</code> (int): Maximum concurrent LLM calls (default: 16)</li> </ul> <p>Example: <pre><code>df.semantic_reduce(\n    user_instruction=\"Summarize the plot structure\",\n    input_column=\"Plot\"\n)\n</code></pre></p>"},{"location":"api/frame/dataframe/#execute-tuplepddataframe-float-float","title":"<code>execute() -&gt; tuple[pd.DataFrame, float, float]</code>","text":"<p>Execute the query plan along the data lineage.</p> <p>Returns:</p> <ul> <li><code>tuple</code>: (output DataFrame, total cost, runtime in seconds)</li> </ul>"},{"location":"api/frame/dataframe/#optimize_and_executeoptim_config-optimizeconfig-none-tuplepddataframe-float-float","title":"<code>optimize_and_execute(optim_config: OptimizeConfig = None) -&gt; tuple[pd.DataFrame, float, float]</code>","text":"<p>Optimize and execute the query plan.</p> <p>Arguments:</p> <ul> <li><code>optim_config</code> (nirvana.OptimizeConfig): configurations for optimization</li> </ul> <p>Returns:</p> <ul> <li><code>tuple</code>: (result DataFrame, total cost, runtime in seconds)</li> </ul>"},{"location":"api/frame/dataframe/#print_lineage_graphop_signature_width-int-100-max_instruction_print_length-int-50","title":"<code>print_lineage_graph(op_signature_width: int = 100, max_instruction_print_length: int = 50)</code>","text":"<p>Print a visual representation of the query.</p> <p>Arguments:</p> <ul> <li><code>op_signature_width</code> (int): Width for operator signatures</li> <li><code>max_instruction_print_length</code> (int): Max length for instruction display</li> </ul>"},{"location":"api/frame/dataframe/#clear_lineage_graph","title":"<code>clear_lineage_graph()</code>","text":"<p>Clear the data lineage graph alongwith the dataframe.</p>"},{"location":"api/ops/filter/","title":"Filter Operation","text":"<p>The Filter operator evaluates an NL condition on each item in a column.</p>"},{"location":"api/ops/filter/#nirvanaopsfilter","title":"nirvana.ops.filter","text":"<p><code>(input_data: pandas.DataFrame, user_instruction: str, input_column: str, func: Callable = None, strategy: Literal[\"plain\", \"fewshot\", \"self-refine\"] = \"plain\", **kwargs) -&gt; FilterOpOutputs</code></p> <p>A function wrapper that invokes <code>FilterOperation.execute(input_data)</code></p>"},{"location":"api/ops/filter/#filteropoutputs","title":"FilterOpOutputs","text":"<p>The type of return value of <code>FilterOperation</code> (base: <code>BaseOpOutputs</code>).</p> <p>Parameters: - <code>output</code> (<code>Iterable[bool]</code>): List of evaluation results - <code>cost</code> (<code>float</code>): Token cost for executing map operation  </p>"},{"location":"api/ops/filter/#filteroperation","title":"FilterOperation","text":"<p>Core class to implement filter operation (base: <code>BaseOperation</code>).</p> <p>Parameters:</p> Name Type Description Default <code>user_instruction</code> <code>str</code> User instruction required <code>input_columns</code> <code>list[str]</code> List of input columns required <code>context</code> <code>dict</code> Additional context information (e.g., demonstrations) for LLM reasoning <code>{}</code> <code>model</code> <code>str</code> LLM backend for operation execution <code>None</code> <code>tool</code> <code>BaseTool</code> Function tools for operation execution <code>None</code> <code>semaphore</code> <code>int</code> Concurrent LLM calls <code>16</code> <code>assertions</code> <code>list[Callable]</code> Assertions/guardrails to constrain behavior of map operation <code>[]</code> <code>strategy</code> <code>Literal[\"plain\", \"fewshot\", \"self-refine\"]</code> The workflow of LLM inference: <code>plain</code> represents a direct LLM inference; <code>fewshot</code> represents LLM inference with few-shot demos (requiring demos in <code>context</code>); <code>self-refine</code> represents self-refinement workflow that gives feedback to the initial generation then refines LLM outputs accordingly <code>\"plain\"</code>"},{"location":"api/ops/filter/#properties","title":"Properties:","text":"<ul> <li><code>dependencies</code> (<code>list(str)</code>): Dependent columns of the filter operation</li> <li><code>generated_fields</code> (<code>list(str)</code>): Names of generated fields of the filter operation</li> <li><code>op_kwargs</code> (<code>dict</code>): arguments in the filter operation</li> </ul>"},{"location":"api/ops/filter/#methods","title":"Methods","text":""},{"location":"api/ops/filter/#executeinput_data-args-kwargs-filteropoutputs","title":"<code>execute(input_data, *args, **kwargs) -&gt; FilterOpOutputs</code>","text":""},{"location":"api/ops/join/","title":"Join Operation","text":"<p>The Join operation joins two tables by keeping tuple pairs that satisfy a natural language condition.</p>"},{"location":"api/ops/join/#nirvanaopsjoin","title":"nirvana.ops.join","text":"<p><code>(left_data: pandas.DataFrame, right_data: pandas.DataFrame, user_instruction: str, left_on: str, right_on: str, how: str = \"inner\", strategy: Literal[\"nest\", \"block\"] = \"nest\", **kwargs) -&gt; JoinOpOutputs</code></p> <p>A function wrapper that invokes <code>JoinOperation.execute(left_data, right_data)</code></p>"},{"location":"api/ops/join/#joinopoutputs","title":"JoinOpOutputs","text":"<p>The type of return value of <code>JoinOperation</code> (base: <code>BaseOpOutputs</code>).</p> <p>Parameters: - <code>joined_pairs</code> (<code>list[tuple]</code>): List of indices pairs of joined records - <code>left_join_keys</code> (<code>list[int]</code>): Join keys for the left table - <code>right_join_keys</code> (<code>list[int]</code>): Join keys for the right table - <code>cost</code> (<code>float</code>): Token cost for executing map operation</p>"},{"location":"api/ops/join/#joinoperation","title":"JoinOperation","text":"<p>Core class to implement join operation (base: <code>BaseOperation</code>).</p> <p>Parameters:</p> Name Type Description Default <code>user_instruction</code> <code>str</code> User instruction required <code>left_on</code> <code>list[str]</code> Input columns from the left table that the operation evaluates on required <code>right_on</code> <code>list[str]</code> Input columns from the right table that the operation evaluates on required <code>how</code> <code>str</code> Join type (<code>inner</code>, <code>left</code>, <code>right</code>) <code>\"inner\"</code> <code>context</code> <code>dict</code> Additional context information (e.g., demonstrations) for LLM reasoning <code>{}</code> <code>model</code> <code>str</code> LLM backend for operation execution <code>None</code> <code>tool</code> <code>BaseTool</code> Function tools for operation execution <code>None</code> <code>semaphore</code> <code>int</code> Concurrent LLM calls <code>16</code> <code>assertions</code> <code>list[Callable]</code> Assertions/guardrails to constrain behavior of map operation <code>[]</code> <code>strategy</code> <code>Literal[\"nest\", \"block\"]</code> The join algorithm adopted the operation: <code>nest</code> represents pair-wise comparisons for nested-loop join; <code>block</code> represents block-wise joined pair identification <code>\"nest\"</code>"},{"location":"api/ops/join/#properties","title":"Properties:","text":"<ul> <li><code>dependencies</code> (<code>list(str)</code>): Dependent columns of the join operation</li> <li><code>generated_fields</code> (<code>list(str)</code>): Names of generated fields of the join operation</li> <li><code>op_kwargs</code> (<code>dict</code>): arguments in the join operation</li> </ul>"},{"location":"api/ops/join/#methods","title":"Methods","text":""},{"location":"api/ops/join/#executeinput_data-args-kwargs-joinopoutputs","title":"<code>execute(input_data, *args, **kwargs) -&gt; JoinOpOutputs</code>","text":""},{"location":"api/ops/map/","title":"Map Operation","text":"<p>The Map operation applies a specified transformation in natural language to each item in a column of input data</p>"},{"location":"api/ops/map/#nirvanaopsmap","title":"nirvana.ops.map","text":"<p><code>( input_data: pandas.DataFrame, user_instruction: str, input_column: str, output_columns: list[str], func: Callable = None, strategy: Literal[\"plain\", \"fewshot\", \"self-refine\"] = \"plain\", **kwargs ) -&gt; MapOpOutputs</code></p> <p>A function wrapper that invokes <code>MapOperation.execute(input_data)</code></p>"},{"location":"api/ops/map/#mapopoutputs","title":"MapOpOutputs","text":"<p>The type of return value of <code>MapOperation</code> (base: <code>BaseOpOutputs</code>).</p> <p>Parameters:</p> <ul> <li><code>field_name</code> (<code>list[str]</code>): List of output column names</li> <li><code>output</code> (<code>dict[str, list]</code>): Output values for the generated fields</li> <li><code>cost</code> (<code>float</code>): Token cost for executing map operation  </li> </ul>"},{"location":"api/ops/map/#mapoperation","title":"MapOperation","text":"<p>Core class to implement map operation (base: <code>BaseOperation</code>).</p> <p>Parameters:</p>"},{"location":"api/ops/map/#parameters","title":"Parameters","text":"Name Type Description Default <code>user_instruction</code> <code>str</code> User instruction required <code>input_columns</code> <code>list[str]</code> List of input columns required <code>output_columns</code> <code>list[str]</code> List of names of generated fields required <code>context</code> <code>dict</code> Additional context information (e.g., demonstrations) for LLM reasoning <code>{}</code> <code>model</code> <code>str</code> LLM backend for operation execution <code>None</code> <code>tool</code> <code>BaseTool</code> Function tools for operation execution <code>None</code> <code>semaphore</code> <code>int</code> Concurrent LLM calls <code>16</code> <code>assertions</code> <code>list[Callable]</code> Assertions/guardrails to constrain behavior of map operation <code>[]</code> <code>strategy</code> <code>Literal[\"plain\", \"fewshot\", \"self-refine\"]</code> The workflow of LLM inference: <code>plain</code> represents a direct LLM inference; <code>fewshot</code> represents LLM inference with few-shot demos (requiring demos in <code>context</code>); <code>self-refine</code> represents self-refinement workflow that gives feedback to the initial generation then refines LLM outputs accordingly <code>\"plain\"</code>"},{"location":"api/ops/map/#properties","title":"Properties:","text":"<ul> <li><code>dependencies</code> (<code>list(str)</code>): Dependent columns of the map operation</li> <li><code>generated_fields</code> (<code>list(str)</code>): Names of generated fields of the map operation</li> <li><code>op_kwargs</code> (<code>dict</code>): arguments in the map operation</li> </ul>"},{"location":"api/ops/map/#methods","title":"Methods","text":""},{"location":"api/ops/map/#executeinput_data-args-kwargs-mapopoutputs","title":"<code>execute(input_data, *args, **kwargs) -&gt; MapOpOutputs</code>","text":""},{"location":"api/ops/rank/","title":"Rank Operation","text":"<p>The Rank operation ranks records in a column of input data based on a natural language condition.</p>"},{"location":"api/ops/rank/#nirvanaopsrank","title":"nirvana.ops.rank","text":"<p><code>(input_data: pandas.DataFrame, user_instruction: str, input_column: str, descend: bool = True, func: Callable = None, **kwargs) -&gt; RankOpOutputs</code></p> <p>A function wrapper that invokes <code>RankOperation.execute(input_data)</code></p>"},{"location":"api/ops/rank/#rankopoutputs","title":"RankOpOutputs","text":"<p>The type of return value of <code>RankOperation</code> (base: <code>BaseOpOutputs</code>).</p> <p>Parameters: - <code>ranked_indices</code> (<code>list[int]</code>): List of indices of sorted records - <code>ranking</code> (<code>list[int]</code>): Ranking of sorted records - <code>cost</code> (<code>float</code>): Token cost for executing map operation  </p>"},{"location":"api/ops/rank/#rankoperation","title":"RankOperation","text":"<p>Core class to implement rank operation (base: <code>BaseOperation</code>).</p> <p>Parameters:</p> Name Type Description Default <code>user_instruction</code> <code>str</code> User instruction required <code>input_columns</code> <code>list[str]</code> Input columns that the rank operation evaluates on required <code>descend</code> <code>bool</code> Whether to sort in descending order (i.e., from best satisfied to least satisfied) <code>True</code> <code>context</code> <code>dict</code> Additional context information (e.g., demonstrations) for LLM reasoning <code>{}</code> <code>model</code> <code>str</code> LLM backend for operation execution <code>None</code> <code>tool</code> <code>BaseTool</code> Function tools for operation execution <code>None</code> <code>semaphore</code> <code>int</code> Concurrent LLM calls <code>16</code> <code>assertions</code> <code>list[Callable]</code> Assertions/guardrails to constrain behavior of map operation <code>[]</code> <code>strategy</code> <code>Literal[\"plain\"]</code> The rank algorithm <code>\"plain\"</code>"},{"location":"api/ops/rank/#properties","title":"Properties:","text":"<ul> <li><code>dependencies</code> (<code>list(str)</code>): Dependent columns of the rank operation</li> <li><code>generated_fields</code> (<code>list(str)</code>): Names of generated fields of the operation</li> <li><code>op_kwargs</code> (<code>dict</code>): arguments in the rank operation</li> </ul>"},{"location":"api/ops/rank/#methods","title":"Methods","text":""},{"location":"api/ops/rank/#executeinput_data-args-kwargs-rankopoutputs","title":"<code>execute(input_data, *args, **kwargs) -&gt; RankOpOutputs</code>","text":""},{"location":"api/ops/reduce/","title":"Reduce Operation","text":"<p>The Reduce operation aggregates multiple values in a given column into a single result according to the user's instruction.</p>"},{"location":"api/ops/reduce/#nirvanaopsreduce","title":"nirvana.ops.reduce","text":"<p><code>(input_data: pandas.DataFrame, user_instruction: str, input_column: str, func: Callable = None, strategy: str = \"plain\", **kwargs) -&gt; ReduceOpOutputs</code></p> <p>A function wrapper that invokes <code>ReduceOperation.execute(input_data)</code></p>"},{"location":"api/ops/reduce/#reduceopoutputs","title":"ReduceOpOutputs","text":"<p>The type of return value of <code>ReduceOperation</code> (base: <code>BaseOpOutputs</code>).</p> <p>Parameters: - <code>output</code> (<code>Any</code>): The aggregation results - <code>cost</code> (<code>float</code>): Token cost for executing map operation  </p>"},{"location":"api/ops/reduce/#reduceoperation","title":"ReduceOperation","text":"<p>Core class to implement reduce operation (base: <code>BaseOperation</code>).</p> <p>Parameters:</p> Name Type Description Default <code>user_instruction</code> <code>str</code> User instruction required <code>input_columns</code> <code>list[str]</code> Input columns that the rank operation evaluates on required <code>context</code> <code>dict</code> Additional context information (e.g., demonstrations) for LLM reasoning <code>{}</code> <code>model</code> <code>str</code> LLM backend for operation execution <code>None</code> <code>tool</code> <code>BaseTool</code> Function tools for operation execution <code>None</code> <code>semaphore</code> <code>int</code> Concurrent LLM calls <code>16</code> <code>assertions</code> <code>list[Callable]</code> Assertions/guardrails to constrain behavior of map operation <code>[]</code> <code>strategy</code> <code>Literal[\"plain\"]</code> LLM inference strategy <code>\"plain\"</code>"},{"location":"api/ops/reduce/#properties","title":"Properties:","text":"<ul> <li><code>dependencies</code> (<code>list(str)</code>): Dependent columns of the reduce operation</li> <li><code>generated_fields</code> (<code>list(str)</code>): Names of generated fields of the reduce operation</li> <li><code>op_kwargs</code> (<code>dict</code>): arguments in the reduce operation</li> </ul>"},{"location":"api/ops/reduce/#methods","title":"Methods","text":""},{"location":"api/ops/reduce/#executeinput_data-args-kwargs-reduceopoutputs","title":"<code>execute(input_data, *args, **kwargs) -&gt; ReduceOpOutputs</code>","text":""},{"location":"api/optimizer/optimizer/","title":"Query Optimization","text":"<p>Nirvana supports two levels of query optimization: logical and physical plan optimization. With a single optimizer, you can optimize both the logical plan and the physical plan.</p>"},{"location":"api/optimizer/optimizer/#optimizeconfig","title":"OptimizeConfig","text":""},{"location":"api/optimizer/optimizer/#optimizer","title":"Optimizer","text":""},{"location":"concepts/data_lineage/","title":"Data Lineage","text":"<p>Data lineage is the core abstraction in Nirvana that enables lazy execution, query optimization, and cost tracking.</p>"},{"location":"concepts/data_lineage/#overview","title":"Overview","text":"<p>Data lineage is represented as a directed acyclic graph (DAG) where: - Nodes represent operators (scan, map, filter, join, reduce, rank) - Edges represent data flow between operators - Each node tracks input/output fields and dependencies</p>"},{"location":"concepts/data_lineage/#lineagenode","title":"LineageNode","text":"<p>The <code>LineageNode</code> class (in <code>nirvana/lineage/abstractions.py</code>) is the fundamental building block:</p> <pre><code>class LineageNode(NodeBase):\n    def __init__(\n        self,\n        op_name: str,\n        op_kwargs: dict,\n        node_fields: dict,\n        datasource: pd.DataFrame | None = None,\n        **kwargs\n    ):\n        self.operator = op_mapping[op_name](**op_kwargs)\n        self.node_fields = NodeFields(**node_fields)\n        self.datasource = datasource\n        self._left_child = None\n        self._right_child = None\n</code></pre> <p>Key Components:</p> <ol> <li>Operator: The actual operation instance (MapOperation, FilterOperation, etc.)</li> <li>NodeFields: Tracks input and output fields:    <pre><code>@dataclass\nclass NodeFields:\n    left_input_fields: list[str]\n    right_input_fields: list[str]\n    output_fields: list[str]\n</code></pre></li> <li>Child Nodes: Left and right children for binary operations (e.g., join)</li> </ol>"},{"location":"concepts/data_lineage/#building-lineage","title":"Building Lineage","text":"<p>When you call semantic operations on a DataFrame, nodes are added to the lineage:</p> <pre><code>df = nv.DataFrame(data)\n\n# Creates a scan node\ndf.initialize()  # Called automatically in __init__\n\n# Adds a map node\ndf.semantic_map(...)  # Creates LineageNode with MapOperation\n\n# Adds a filter node\ndf.semantic_filter(...)  # Creates LineageNode with FilterOperation\n</code></pre> <p>The <code>LineageMixin</code> (in <code>nirvana/lineage/mixin.py</code>) provides the lineage management:</p> <pre><code>class LineageMixin:\n    def initialize(self):\n        # Create scan node\n        node = LineageNode(\n            op_name=\"scan\",\n            op_kwargs={\"source\": \"dataframe\", \"output_columns\": self.columns},\n            node_fields={\"left_input_fields\": [], \"right_input_fields\": [], \"output_fields\": self.columns},\n            datasource=self._data\n        )\n        self.leaf_node = node\n\n    def add_operator(self, op_name: str, op_kwargs: dict, data_kwargs: dict, **kwargs):\n        node = LineageNode(op_name, op_kwargs=op_kwargs, node_fields=data_kwargs)\n        if op_name == \"join\":\n            node.set_left_child(self.leaf_node)\n            node.set_right_child(kwargs[\"other\"].leaf_node)\n        else:\n            node.set_left_child(self.leaf_node)\n        self.leaf_node = node\n</code></pre>"},{"location":"concepts/data_lineage/#execution-model","title":"Execution Model","text":"<p>Execution follows a post-order traversal of the lineage graph:</p> <pre><code>def execute_along_lineage(leaf_node: LineageNode):\n    def _execute_node(node: LineageNode) -&gt; pd.DataFrame:\n        # Recursively execute children first\n        if node.left_child:\n            left_output = _execute_node(node.left_child)\n        if node.right_child:\n            right_output = _execute_node(node.right_child)\n\n        # Execute current node\n        if node.op_name == \"scan\":\n            return node.datasource\n        elif node.op_name == \"join\":\n            return node.run([left_output, right_output])\n        else:\n            return node.run(left_output)\n\n    return _execute_node(leaf_node)\n</code></pre> <p>Execution Flow:</p> <ol> <li>Scan: Returns the datasource DataFrame</li> <li>Unary Operations (map, filter, reduce): Execute on left child output</li> <li>Binary Operations (join): Execute on both children's outputs</li> </ol>"},{"location":"concepts/data_lineage/#node-execution","title":"Node Execution","text":"<p>Each <code>LineageNode</code> has a <code>run()</code> method that:</p> <ol> <li>Executes the operator's <code>execute()</code> method</li> <li>Collates the results into a DataFrame</li> <li>Returns a <code>NodeOutput</code> with the result, cost, and metadata</li> </ol> <pre><code>async def run(self, input: pd.DataFrame | list[pd.DataFrame] | None = None) -&gt; NodeOutput:\n    if self.op_name == \"scan\":\n        return NodeOutput(output=self.datasource, cost=0.0)\n\n    elif self.op_name == \"join\":\n        op_outputs = await self.operator.execute(left_data=input[0], right_data=input[1])\n        # Collate join results\n        input[0][\"keys\"] = op_outputs.left_join_keys\n        input[1][\"keys\"] = op_outputs.right_join_keys\n        output = input[0].join(input[1], on=\"keys\", how=self.operator.how).drop(\"keys\", axis=1)\n        return NodeOutput(output=output, cost=op_outputs.cost)\n\n    elif self.op_name == \"filter\":\n        op_outputs = await self.operator.execute(input_data=input)\n        if op_outputs.output is None:\n            return NodeOutput(output=input, cost=op_outputs.cost)\n        return NodeOutput(output=input[op_outputs.output], cost=op_outputs.cost)\n\n    # ... other operators\n</code></pre>"}]}